{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import rouskinhf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot showing the quality of our datasets\n",
    "\n",
    "Compare replicates:\n",
    "- R2 score between normalized DMS signals (first row of subplot)\n",
    "- F1 score between replicate + RNAstructure (second row)\n",
    "\n",
    "Then bootstrap from the DMS by adding noise proportional to the confidence interval, then predicting the structure with the noisy DMS. Compute the F1 score between the structures (third row of the subplot)\n",
    "\n",
    "Use pri_miRNA and human_mRNA (called UTR previously). Combine them in one plot, or separate them in two columns if realy different\n",
    "\n",
    "**Assigned to**: Yves\n",
    "\n",
    "Use Ploty, and a white background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dataset (no need to re-run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load refs from HF\n",
    "refs = list(rouskinhf.get_dataset('human_mRNA').keys()) + list(rouskinhf.get_dataset('pri_miRNA').keys())\n",
    "\n",
    "# load reps data from local\n",
    "pri = pd.read_feather('pri_miRNA_normalized.feather').drop(columns=['index'])\n",
    "pri['dataset'] = 'Pri-miRNA'\n",
    "mrna = pd.read_feather('mRNA_normalized.feather').drop(columns=['index'])\n",
    "mrna['dataset'] = 'Human mRNA'\n",
    "df = pd.concat([pri, mrna])\n",
    "\n",
    "# keep only reps that are in HF\n",
    "df = df[df['replicate'] != 'Untreated']\n",
    "df = df[df['reference'].isin(refs)].reset_index(drop=True)\n",
    "\n",
    "# count the number of reference per sample\n",
    "df['number_of_replicates'] = df.groupby(['reference', 'dataset', 'plate'])['reference'].transform('count')\n",
    "\n",
    "# Count the amount of available reps per dataset\n",
    "ref_per_sample_per_dataset = {}\n",
    "for dataset in df['dataset'].unique():\n",
    "    loc_df = df[df['dataset']==dataset]\n",
    "    ref_per_sample_per_dataset[dataset] = {k[0]: v for k, v in dict(loc_df.value_counts(['number_of_replicates']).sort_index()).items()} \n",
    "\n",
    "# drop the reference with less than 2 sample \n",
    "l = len(df)\n",
    "df = df[df['number_of_replicates'] == 2]\n",
    "print(\"drop {}/{} references\".format(l - len(df), l))\n",
    "\n",
    "# Run RNAstructure\n",
    "rnastructure_path = '/Users/yvesmartin/lib/RNAstructure/exe'\n",
    "\n",
    "def file_name(stage): \n",
    "    return f'{stage}/{file_name.ref}_{file_name.replicate}.{stage}'\n",
    "\n",
    "for stage in ['fasta', 'shape', 'ct', 'dot']:\n",
    "    os.makedirs(stage, exist_ok=True)\n",
    "    \n",
    "def predict_structure(seq, ref, rep, dms=None):\n",
    "    file_name.ref = ref\n",
    "    file_name.replicate = rep\n",
    "    os.system(f'echo \">{ref}\\n{seq}\" >{file_name(\"fasta\")}')\n",
    "    if dms is None:\n",
    "        dms = np.zeros(len(seq))# * -1000.\n",
    "    dms = pd.DataFrame({'dms': [float(d) for d in dms], 'seq': list(seq)})\n",
    "    dms.index = dms.index + 1\n",
    "    dms = dms[dms['seq'].isin(['A', 'C'])]['dms']\n",
    "    dms.to_csv(file_name('shape'), sep='\\t', header=False)\n",
    "    os.system(f\"{rnastructure_path}/fold {file_name('fasta')} {file_name('ct')} --DMS {file_name('shape')}\")\n",
    "    os.system(f\"{rnastructure_path}/ct2dot {file_name('ct')}  -1 {file_name('dot')}\" )\n",
    "    with open(file_name('dot')) as f:\n",
    "        lines = f.readlines()\n",
    "    energy = float(lines[0].split()[2])\n",
    "    structure = lines[2].strip()\n",
    "    return energy, structure\n",
    "\n",
    "\n",
    "for i, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    seq, ref, rep, dms = row[['sequence', 'reference', 'replicate', 'sub_rate']]\n",
    "    energy, structure = predict_structure(seq, ref, rep, dms)\n",
    "    df.loc[i, 'energy'] = energy\n",
    "    df.loc[i, 'structure'] = structure\n",
    "    \n",
    "# read RNAstructure output\n",
    "def read_dot(dot_file):\n",
    "    with open(dot_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    energy, structure = [], []\n",
    "\n",
    "    def get_energy(line):\n",
    "        return float(line.split(' ')[2].strip())\n",
    "\n",
    "    energy.append(get_energy(lines[0]))\n",
    "    structure.append(lines[2].strip())\n",
    "    \n",
    "    for line in lines[3:]:\n",
    "        if line.startswith('>ENERGY'):\n",
    "            energy.append(get_energy(line))\n",
    "        else:\n",
    "            structure.append(line.strip())\n",
    "    \n",
    "    assert len(energy) == len(structure)\n",
    "    return energy, structure\n",
    "\n",
    "rna_pred = []\n",
    "for file in os.listdir('dot'):\n",
    "    energies, structures = read_dot(f'dot/{file}')\n",
    "    for idx, (s, e) in enumerate(zip(structures, energies)):\n",
    "        rna_pred.append({\n",
    "            'reference': file[:-6],\n",
    "            'structure': s,\n",
    "            'energies': e,\n",
    "            'replicate': file.split('_')[-1].split('.')[0],\n",
    "            'rank': idx\n",
    "        })\n",
    "    \n",
    "rna_pred = pd.DataFrame(rna_pred)\n",
    "\n",
    "# merge with df\n",
    "df = pd.merge(df, rna_pred, on=['reference', 'replicate'], how='inner')\n",
    "\n",
    "df.to_feather('data_quality.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot replicates distribution per dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "ref_per_sample_per_dataset = pd.DataFrame(ref_per_sample_per_dataset)\n",
    "ref_per_sample_per_dataset.index = ['No replicate', '1 replicate']\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=ref_per_sample_per_dataset.columns, specs=[[{'type':'domain'}, {'type':'domain'}]])\n",
    "\n",
    "for i, col in enumerate(ref_per_sample_per_dataset.columns):\n",
    "    fig.add_trace(\n",
    "        go.Pie(\n",
    "            labels=ref_per_sample_per_dataset.index, \n",
    "            values=ref_per_sample_per_dataset[col],\n",
    "            name=col,\n",
    "            textinfo='label+percent',\n",
    "            textposition='auto',\n",
    "            rotation=270,\n",
    "    ), row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Number of replicates per reference in each dataset\",\n",
    "    width=800,\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "df_all = pd.read_feather('data_quality.feather')\n",
    "df = df_all.sort_values('energies').groupby(['reference', 'replicate']).first().reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def dot2bool(dot):\n",
    "    return np.array([1 if c == '.' else 0 for c in dot])\n",
    "\n",
    "def compute_score_between_replicates(df, score):\n",
    "    scores = []\n",
    "    for (ref, plate), group in tqdm.tqdm(df.groupby(['reference', 'plate']), total=len(df['reference'].unique())):\n",
    "        A = group[group['replicate'] == 'A']\n",
    "        B = group[group['replicate'] == 'B']\n",
    "        dataset = group['dataset'].values[0]\n",
    "        scores.append({\n",
    "            'reference': ref,\n",
    "            'plate': plate,\n",
    "            'replicate': 'A',\n",
    "            score.name: score(A, B),\n",
    "            'dataset': dataset\n",
    "        })\n",
    "        scores.append({\n",
    "            'reference': ref,\n",
    "            'plate': plate,\n",
    "            'replicate': 'B',\n",
    "            score.name: score(B, A),\n",
    "            'dataset': dataset\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(scores)\n",
    "\n",
    "def plot_score_histogram(df, scores, score, min_X):\n",
    "    fig = go.Figure()\n",
    "    for name, dataset in scores.groupby('dataset'):\n",
    "        fig.add_trace(go.Histogram(x=dataset[score.name], name=name, \n",
    "                            xbins=dict(start=min_X, end=1, size=0.05),\n",
    "                            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='{} score (N={}, # of {} scores < {} = {}) for df: {}'.format(score.name, len(scores), score.name, min_X, len(scores[scores[score.name] < min_X]), df.custom_name),\n",
    "        xaxis_title=score.name,\n",
    "        yaxis_title='count',\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1,\n",
    "        xaxis_range=[min_X, 1],\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "def violin_plot(df, scores, score, min_X):  \n",
    "    fig = go.Figure()\n",
    "    for name, dataset in scores.groupby('dataset'):\n",
    "        fig.add_trace(go.Violin(x=dataset[score.name], name=name + ' (N={})'.format(len(dataset)),\n",
    "                            box_visible=True,\n",
    "                            meanline_visible=True,\n",
    "                            ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title='{} score distribution between replicates'.format(score.name),\n",
    "        xaxis_title=score.name + ' score',\n",
    "        # yaxis_title='dataset',\n",
    "        bargap=0.2,\n",
    "        bargroupgap=0.1,\n",
    "        xaxis_range=[min_X, 1],\n",
    "        showlegend=False,\n",
    "        width=800,    \n",
    "        paper_bgcolor='white',  # Background color of the entire plot\n",
    "        plot_bgcolor='white',  # Background color of the plot area\n",
    "        # add a frame\n",
    "        margin=dict(l=50, r=50, t=50, b=50),  # Adjust margins\n",
    "        xaxis=dict(\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='lightgrey',\n",
    "            mirror=True,\n",
    "            showgrid=False,\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            showline=True,\n",
    "            linewidth=2,\n",
    "            linecolor='lightgrey',\n",
    "            mirror=True,\n",
    "            showgrid=False,\n",
    "            gridcolor='white',\n",
    "            gridwidth=2,\n",
    "        ),\n",
    "        font=dict(\n",
    "        size=18,\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "    \n",
    "def normalize(x, mask=None):\n",
    "    x = np.array(x)\n",
    "    mask = x != -1000. if mask is None else mask\n",
    "    per90 = np.percentile(x, 90)\n",
    "    y = np.clip(x[mask] / per90, 0, 1)\n",
    "    x[mask] = y\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add RNAstructure normalized structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rnastructure import RNAstructure\n",
    "rna = RNAstructure()\n",
    "\n",
    "def normalized_structure_prediction(row):\n",
    "    dms = normalize(row['sub_rate'])\n",
    "    seq = row['sequence']\n",
    "    return rna.predictStructure(seq, dms=dms)\n",
    "\n",
    "for i, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    df.loc[i, 'structure_normalized'] = normalized_structure_prediction(row)\n",
    "    \n",
    "df.to_feather('data_quality.feather')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def auroc(row):\n",
    "    sig = row['sub_rate']\n",
    "    mask = sig != -1000.\n",
    "    sig = sig[mask]\n",
    "    structure = dot2bool(row['structure'])[mask]\n",
    "    return roc_auc_score(structure, sig)\n",
    "\n",
    "df_all['auroc'] = df_all.apply(lambda x: auroc(x), axis=1)\n",
    "df_best = df_all.sort_values('auroc', ascending=False).groupby(['reference', 'plate','replicate']).first().reset_index()\n",
    "\n",
    "df.custom_name = 'lowest predicted energy'\n",
    "df_best.custom_name = 'best auroc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def r2_score_obj(x, y):\n",
    "    A, B = x['sub_rate'].values[0], y['sub_rate'].values[0]\n",
    "    mask = (A != -1000.) & (B != -1000.)\n",
    "    A, B = A[mask], B[mask]\n",
    "    return r2_score(A, B)\n",
    "\n",
    "r2_score_obj.name = 'R2'\n",
    "scores = compute_score_between_replicates(df, r2_score_obj)\n",
    "# style like a paper\n",
    "fig = violin_plot(df, scores, r2_score_obj, 0.)\n",
    "# style the plot like a pape\n",
    "    \n",
    "\n",
    "fig.show()\n",
    "# violin_plot(df_best, compute_score_between_replicates(df_best, r2_score_obj), r2_score_obj, 0.).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import f1_score\n",
    "from sklearn.metrics import f1_score as f1_score_sklearn\n",
    "\n",
    "import rnastructure\n",
    "rna = rnastructure.RNAstructure()\n",
    "\n",
    "def f1_score(x0, x1):\n",
    "    x0, x1 = x0['structure'].values[0], x1['structure'].values[0]\n",
    "    return f1_score_sklearn(dot2bool(x0), dot2bool(x1))\n",
    "\n",
    "f1_score.name = 'f1'\n",
    "\n",
    "fig = violin_plot(df, compute_score_between_replicates(df, f1_score), f1_score, 0.).update_layout(width=800)\n",
    "\n",
    "# make text bigger\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson_score(x, y):\n",
    "    A, B = x['sub_rate'].values[0], y['sub_rate'].values[0]\n",
    "    mask = (A != -1000.) & (B != -1000.)\n",
    "    A, B = A[mask], B[mask]\n",
    "    return np.corrcoef(A, B)[0, 1]\n",
    "\n",
    "pearson_score.name = 'pearson'\n",
    "\n",
    "\n",
    "violin_plot(df, compute_score_between_replicates(df, pearson_score), pearson_score, 0.).update_layout(width=800).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coeff_of_determination(x, y):\n",
    "    A, B = x['sub_rate'].values[0], y['sub_rate'].values[0]\n",
    "    mask = (A != -1000.) & (B != -1000.)\n",
    "    A, B = A[mask], B[mask]\n",
    "    return np.corrcoef(A, B)[0, 1]**2\n",
    "\n",
    "coeff_of_determination.name = 'coeff_of_determination'\n",
    "violin_plot(df, compute_score_between_replicates(df, coeff_of_determination), coeff_of_determination, 0.).update_layout(width=800).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping on F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pri_miRNA = pd.DataFrame.from_dict(rouskinhf.get_dataset('pri_miRNA'), orient='index').reset_index().rename(columns={'index':'reference'})\n",
    "df_pri_miRNA['dataset'] = 'pri_miRNA'\n",
    "\n",
    "# load human_mRNA from HF\n",
    "df_human_mRNA = pd.DataFrame.from_dict(rouskinhf.get_dataset('human_mRNA'), orient='index').reset_index().rename(columns={'index':'reference'})\n",
    "df_human_mRNA['dataset'] = 'human_mRNA'\n",
    "\n",
    "df_hf = pd.concat([df_pri_miRNA, df_human_mRNA])\n",
    "\n",
    "# get the number of reads from df\n",
    "df_hf['reads'] = df_hf['reference'].apply(lambda x: df[df['reference'] == x]['reads'].values[0])\n",
    "\n",
    "df_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a bootstrapping function using a binomial distribution\n",
    "\n",
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "n_bootstrap = 10\n",
    "\n",
    "def bootstrap(n, p, N=n_bootstrap):\n",
    "    l = len(p)\n",
    "    n = (np.ones(l) * n).astype(int)\n",
    "    return np.random.binomial(n, p, (N, l)) / n\n",
    "\n",
    "f1_scores_total = {}\n",
    "r2_scores_total = {}\n",
    "for _, line in tqdm.tqdm(df_hf.iterrows(), total=len(df_hf)):\n",
    "    reference, sequence, dms, dataset, reads = line[['reference', 'sequence', 'dms', 'dataset', 'reads']]\n",
    "    dms = np.array(dms) \n",
    "    f1_scores_local = []\n",
    "    r2_scores_local = []\n",
    "    dms_boot = bootstrap(reads, dms)\n",
    "    for dms in dms_boot:\n",
    "        pred = rna.predictStructure(sequence, dms=dms)\n",
    "        f1_scores_local.append(f1_score_sklearn(dot2bool(pred), dot2bool(pred)))\n",
    "        r2_scores_local.append(r2_score(dms, pred))\n",
    "        \n",
    "    f1_scores_total[reference] = f1_scores_local\n",
    "    r2_scores_total[reference] = r2_scores_local\n",
    "    \n",
    "df_hf['f1_scores'] = df_hf['reference'].apply(lambda x: f1_scores_total[x])\n",
    "df_hf['r2_scores'] = df_hf['reference'].apply(lambda x: r2_scores_total[x])\n",
    "\n",
    "# dump the data\n",
    "df_hf.to_feather('data_quality_bootstrapping.feather')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
